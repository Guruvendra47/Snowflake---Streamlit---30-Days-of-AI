# ğŸ—“ï¸ Day 10 â€” Your First Chatbot (with State)

## ğŸ¯ Goal of the Day

For today's challenge, our goal is to **combine chat elements and Session State** to build a chatbot that **remembers the conversation**.

By doing this, we:

* ğŸ’¬ Use `st.chat_message` to render chat bubbles
* ğŸ§  Store messages in `st.session_state`
* ğŸ” Preserve conversation history across interactions

Once completed, we will have a **working chatbot** that no longer forgets what was said before.

---

## ğŸ§© See the Code

```python
import streamlit as st
import json
from snowflake.snowpark.functions import ai_complete

# Connect to Snowflake
try:
    # Works in Streamlit in Snowflake
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    # Works locally and on Streamlit Community Cloud
    from snowflake.snowpark import Session
    session = Session.builder.configs(st.secrets["connections"]["snowflake"]).create()

def call_llm(prompt_text: str) -> str:
    """Call Snowflake Cortex LLM."""
    df = session.range(1).select(
        ai_complete(model="claude-3-5-sonnet", prompt=prompt_text).alias("response")
    )
    response_raw = df.collect()[0][0]
    response_json = json.loads(response_raw)
    # Extract text from response
    if isinstance(response_json, dict):
        return response_json.get("choices", [{}])[0].get("messages", "")
    return str(response_json)

st.title(":material/chat: My First Chatbot")

# Initialize the messages list in session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display all messages from history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Chat input
if prompt := st.chat_input("What would you like to know?"):
    # Add user message to state
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.write(prompt)
    
    # Generate and display assistant response
    with st.chat_message("assistant"):
        response = call_llm(prompt)
        st.write(response)
    
    # Add assistant response to state
    st.session_state.messages.append({"role": "assistant", "content": response})

st.divider()
st.caption("Day 10: Your First Chatbot (with State) | 30 Days of AI")
```

---

## ğŸ“˜ Explanation

### ğŸ” How It Works: Step-by-Step

Letâ€™s break down how memory is added to the chatbot.

---

## 1ï¸âƒ£ Initialize Message Storage

```python
st.title(":material_chat: My First Chatbot")

# Initialize the messages list in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
```

* ğŸ§  `st.session_state.messages = []`:

  * Creates a **persistent list** to store the conversation
  * Each item is a dictionary with:

    * `role` â†’ "user" or "assistant"
    * `content` â†’ message text

* ğŸ“Œ This message format is **industry standard** (used by OpenAI, Anthropic, etc.)

* âœ… `if "messages" not in ...`:

  * Ensures initialization happens **only once**
  * Prevents wiping chat history on every rerun

---

## 2ï¸âƒ£ Display Chat History

```python
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])
```

* ğŸ” Loops through all stored messages
* ğŸ’¬ `st.chat_message(message["role"])`:

  * Automatically renders the correct chat bubble
* ğŸ“œ This redraws the **entire conversation** on every rerun

---

## 3ï¸âƒ£ Handle New Messages

```python
if prompt := st.chat_input("What would you like to know?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
```

* ğŸ§  **Walrus operator (`:=`)**:

  * Assigns and checks the input in one line

* â• `.append(...)`:

  * Adds the user message to session state
  * Must happen **before** rendering the response

---

## 4ï¸âƒ£ Generate and Store Assistant Response

```python
with st.chat_message("assistant"):
    response = call_llm(prompt)
    st.write(response)

st.session_state.messages.append({"role": "assistant", "content": response})
```

* ğŸ¤– `call_llm(...)`:

  * Calls **Snowflake Cortex** using `ai_complete()`

* ğŸ’¾ Second `.append(...)`:

  * Stores the assistantâ€™s reply
  * Completes one full conversation turn

### â“ Why SQL-based `ai_complete()`?

* âœ… Works in **all environments**:

  * Streamlit in Snowflake
  * Streamlit Community Cloud
  * Local development

* âŒ Python SDK can fail due to SSL issues

* âœ”ï¸ SQL-based approach is **universally reliable**

---

## ğŸ–¥ï¸ Final Result

When this code runs, you now have:

* ğŸ’¬ A real chatbot UI
* ğŸ§  Memory across interactions
* ğŸ“œ A visible conversation history

---

## âš ï¸ Whatâ€™s Missing? (Room for Improvement)

While functional, this chatbot has limitations:

### Current Limitations

* âŒ No visual feedback while waiting
* âŒ Responses appear all at once
* âŒ No conversation statistics
* âŒ No reset / clear chat button
* âŒ Generic appearance
* âŒ No error handling

ğŸš€ Donâ€™t worry â€” **all of this will be fixed** in upcoming lessons as we move toward a **productionâ€‘ready chatbot**.

---

## ğŸ“š Resources

* ğŸ“˜ **Build Conversational Apps**
* ğŸ“˜ **Cortex Complete Function**


