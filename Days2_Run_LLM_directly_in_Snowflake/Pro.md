
## ğŸ” How It Works â€” Step by Step

### 1ï¸âƒ£ Import Libraries & Connect to Snowflake

```python
import streamlit as st
from snowflake.snowpark.functions import ai_complete
import json
```

* `streamlit`: Builds the UI
* `ai_complete`: Snowflake Cortex function to call LLMs
* `json`: Used to parse the AI response

### Environment Detection Logic

```python
try:
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    from snowflake.snowpark import Session
    session = Session.builder.configs(
        st.secrets["connections"]["snowflake"]
    ).create()
```

âœ… This makes the app **portable**:

* Works in **Streamlit in Snowflake**
* Works **locally**
* Works on **Streamlit Community Cloud**

---

### 2ï¸âƒ£ Choose Model & Capture User Input

```python
model = "claude-3-5-sonnet"
prompt = st.text_input("Enter your prompt:")
```

* `model`: Specifies which Cortex LLM to use
* `st.text_input`: Captures user input from the UI

---

### 3ï¸âƒ£ Run LLM Inference (Button Click)

```python
if st.button("Generate Response"):
    df = session.range(1).select(
        ai_complete(model=model, prompt=prompt).alias("response")
    )
```

ğŸ§  Key idea:

* `session.range(1)` creates a **single-row DataFrame**
* The LLM is executed as part of a **Snowpark DataFrame operation**
* Output is stored in a column named `response`

ğŸ‘‰ Think of it as:

> â€œRun the AI like a SQL function.â€

---

### 4ï¸âƒ£ Fetch & Display the AI Response

```python
response_raw = df.collect()[0][0]
response = json.loads(response_raw)
st.write(response)
```

* `.collect()` executes the query in Snowflake
* Cortex returns **JSON**, not plain text
* `json.loads()` converts it into a Python dictionary
* `st.write()` displays the result

Example raw response:

```json
{"choices":[{"messages":"Hello! How can I help you?"}]}
```

---

## ğŸ¤” Why Use `ai_complete()`?

**Advantages**

* Integrates naturally with Snowpark DataFrames
* Ideal for data pipelines and SQL-style workflows
* Secure execution inside Snowflake

**Limitations**

* Returns JSON (needs parsing)
* No streaming support

ğŸ‘‰ In **Day 3**, we will use the **Python `Complete()` API**, which:

* Is simpler
* Supports streaming responses

---

## ğŸ“Œ Key Takeaways (Interview-Ready)

* Snowflake Cortex allows **LLMs to run directly inside Snowflake**
* `AI_COMPLETE` is a **Snowpark-native AI function**
* Streamlit + Cortex = **secure AI apps without external APIs**
* Data never leaves Snowflake â†’ **enterprise-grade security**

---

## ğŸ“š Resources

* ğŸ“˜ Snowflake Cortex LLM Functions
* ğŸ“˜ COMPLETE Function Reference
* ğŸ“˜ Available LLM Models

---
