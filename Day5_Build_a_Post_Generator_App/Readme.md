# ğŸ—“ï¸ Day 5 â€” Build a Post Generator App

## ğŸ¯ Goal of the Day

For today's challenge, our goal is to build a **Streamlit web application** that generates a **professional LinkedIn post**.

We need to:

* ğŸ”— Accept user input such as a **content URL**
* ğŸ­ Allow the user to choose a **tone** (Professional, Casual, Funny)
* ğŸ“ Control the **length** of the post
* ğŸ¤– Call **Snowflake Cortex AI** from inside the Streamlit app
* ğŸ“ Display the generated LinkedIn post in the UI

---

## ğŸ§© See the Code

```python
import streamlit as st
import json
from snowflake.snowpark.functions import ai_complete

# Connect to Snowflake
try:
    # Works in Streamlit in Snowflake
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    # Works locally and on Streamlit Community Cloud
    from snowflake.snowpark import Session
    session = Session.builder.configs(st.secrets["connections"]["snowflake"]).create()

# Cached LLM Function
@st.cache_data
def call_cortex_llm(prompt_text):
    """Makes a call to Cortex AI with the given prompt."""
    model = "claude-3-5-sonnet"
    df = session.range(1).select(
        ai_complete(model=model, prompt=prompt_text).alias("response")
    )
    
    # Get and parse response
    response_raw = df.collect()[0][0]
    response_json = json.loads(response_raw)
    return response_json

# --- App UI ---
st.title(":material/post: LinkedIn Post Generator")

# Input widgets
content = st.text_input("Content URL:", "https://docs.snowflake.com/en/user-guide/views-semantic/overview")
tone = st.selectbox("Tone:", ["Professional", "Casual", "Funny"])
word_count = st.slider("Approximate word count:", 50, 300, 100)

# Generate button
if st.button("Generate Post"):
    # Construct the prompt
    prompt = f"""
    You are an expert social media manager. Generate a LinkedIn post based on the following:

    Tone: {tone}
    Desired Length: Approximately {word_count} words
    Use content from this URL: {content}

    Generate only the LinkedIn post text. Use dash for bullet points.
    """
    
    response = call_cortex_llm(prompt)
    st.subheader("Generated Post:")
    st.markdown(response)

# Footer
st.divider()
st.caption("Day 5: Build a Post Generator App | 30 Days of AI")
```

---

## ğŸ“˜ Explanation

### ğŸ” How It Works: Step-by-Step

Let's break down what each part of the code does.

---

## 1ï¸âƒ£ Setup and Snowflake Cortex AI Function

```python
import streamlit as st
import json
from snowflake.snowpark.functions import ai_complete

# Connect to Snowflake
try:
    # Works in Streamlit in Snowflake
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    # Works locally and on Streamlit Community Cloud
    from snowflake.snowpark import Session
    session = Session.builder.configs(st.secrets["connections"]["snowflake"]).create()

# Cached LLM Function
@st.cache_data
def call_cortex_llm(prompt_text):
    """Makes a call to Cortex AI with the given prompt."""
    model = "claude-3-5-sonnet"
    df = session.range(1).select(
        ai_complete(model=model, prompt=prompt_text).alias("response")
    )

    # Get and parse response
    response_raw = df.collect()[0][0]
    response_json = json.loads(response_raw)
    return response_json
```

* ğŸ“¦ `import streamlit as st`: Imports Streamlit to build the web application UI and logic
* ğŸ¤– `ai_complete`: Snowpark function used to interact with **Snowflake Cortex AI (LLMs)**
* ğŸ” **try / except block**: Automatically detects the environment and connects appropriately (Streamlit in Snowflake, local, or Community Cloud)
* ğŸ”Œ `session`: The active Snowflake connection used to execute queries
* ğŸ§  `@st.cache_data`: Caches the LLM response so the AI call is not repeated unless the input prompt changes
* ğŸš€ `ai_complete(model=model, prompt=prompt_text)`: Sends the user's prompt to the specified model (**claude-3-5-sonnet**) and returns generated text

---

## 2ï¸âƒ£ Building the Streamlit UI and User Input

```python
# --- App UI ---
st.title("LinkedIn Post Generator")

# Input widgets
content = st.text_input("Content URL:", "https://docs.snowflake.com/en/user-guide/views-semantic/overview")
tone = st.selectbox("Tone:", ["Professional", "Casual", "Funny"])
word_count = st.slider("Approximate word count:", 50, 300, 100)

# Generate button
if st.button("Generate Post"):
```

* ğŸ·ï¸ `st.title(...)`: Sets the main title of the application
* ğŸ”— `st.text_input(...)`: Text field where the user pastes the content URL
* ğŸ­ `st.selectbox(...)`: Dropdown menu to select the desired tone
* ğŸ“ `st.slider(...)`: Slider to control the approximate length of the post
* ğŸ”˜ `st.button("Generate Post")`: Executes the logic only when the user clicks the button

---

## 3ï¸âƒ£ Prompt Construction and Output Display

```python
# Construct the prompt
prompt = f"""
You are an expert social media manager. Generate a LinkedIn post based on the following:

Tone: {tone}
Desired Length: Approximately {word_count} words
Use content from this URL: {content}

Generate only the LinkedIn post text. Use dash for bullet points.
"""

response = call_cortex_llm(prompt)
st.subheader("Generated Post:")
st.markdown(response)
```

* ğŸ§© `prompt = f"""..."""`: Dynamically builds the LLM prompt using user inputs
* ğŸ¯ Role-based instruction (`expert social media manager`) helps improve output quality
* ğŸ” `call_cortex_llm(prompt)`: Sends the final prompt to Snowflake Cortex AI
* ğŸ§¾ `st.subheader(...)`: Clearly labels the output section
* ğŸ“ `st.markdown(response)`: Displays the generated LinkedIn post with Markdown formatting

---

## ğŸ–¥ï¸ Final Result

When this code runs, you will see:

* A clean Streamlit web page
* Input fields for URL, tone, and length
* A **Generate Post** button
* A professionally written LinkedIn post displayed below

---

## ğŸ“š Resources

* ğŸ“˜ **Snowflake Cortex LLM Functions**
* ğŸ“˜ **st.text_input Documentation**
* ğŸ“˜ **st.selectbox Documentation**
* ğŸ“˜ **st.slider Documentation**


